{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGdzdZuC_2-8",
        "outputId": "35e2cd78-2967-47aa-c5d9-967df71e639e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final CSV saved as labelled_with_textblob_sentiment.csv\n",
            "                                             Heading Sentiment\n",
            "0  free speech not hate speech madras high court ...  Positive\n",
            "1  comment take context say us cop mock indian st...  Negative\n",
            "2  first meeting one nation one election committe...  Positive\n",
            "3  us airlines flight depressurize midair plummet...  Positive\n",
            "4  terrorist kill security force foil infiltratio...  Positive\n",
            "✅ Final CSV saved as labelled_with_textblob_sentiment.csv\n",
            "                                             Heading Sentiment\n",
            "0  free speech not hate speech madras high court ...  Positive\n",
            "1  comment take context say us cop mock indian st...  Negative\n",
            "2  first meeting one nation one election committe...  Positive\n",
            "3  us airlines flight depressurize midair plummet...  Positive\n",
            "4  terrorist kill security force foil infiltratio...  Positive\n"
          ]
        }
      ],
      "source": [
        "!pip install textblob --quiet\n",
        "\n",
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# -----------------------------\n",
        "# STEP 1: Load dataset\n",
        "# -----------------------------\n",
        "df = pd.read_csv(\"/content/labelled.csv\")   # contains [\"Heading\",\"Body\",\"Category\",\"URL\"]\n",
        "\n",
        "# Use Heading + Body as text input\n",
        "df[\"text\"] = df[\"Heading\"].astype(str) + \" \" + df[\"Body\"].astype(str)\n",
        "\n",
        "# -----------------------------\n",
        "# STEP 2: Sentiment using TextBlob\n",
        "# -----------------------------\n",
        "def get_sentiment(text):\n",
        "    analysis = TextBlob(str(text))\n",
        "    polarity = analysis.sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return \"Positive\"\n",
        "    elif polarity < 0:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "df[\"Sentiment\"] = df[\"text\"].apply(get_sentiment)\n",
        "\n",
        "# -----------------------------\n",
        "# STEP 3: Save CSV\n",
        "# -----------------------------\n",
        "output_file = \"labelled_with_textblob_sentiment.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"✅ Final CSV saved as {output_file}\")\n",
        "print(df[[\"Heading\", \"Sentiment\"]].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROberta"
      ],
      "metadata": {
        "id": "UXx8DJbptiyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch scipy --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "import urllib.request, csv\n",
        "\n"
      ],
      "metadata": {
        "id": "uAZlXgAKBjFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# STEP 1: Load your dataset\n",
        "# -----------------------------\n",
        "df = pd.read_csv(\"/content/labelled.csv\")   # should have Heading, Body, Category, URL\n",
        "\n",
        "# Use Heading + Body as text input\n",
        "df[\"text\"] = df[\"Heading\"].astype(str) + \" \" + df[\"Body\"].astype(str)\n",
        "\n"
      ],
      "metadata": {
        "id": "ypIawJVQH4my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# STEP 2: Load RoBERTa sentiment model\n",
        "# -----------------------------\n",
        "task = \"sentiment\"\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
        "\n",
        "# Load tokenizer & model\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "\n",
        "# Download label mapping\n",
        "labels = []\n",
        "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
        "with urllib.request.urlopen(mapping_link) as f:\n",
        "    html = f.read().decode(\"utf-8\").split(\"\\n\")\n",
        "    csvreader = csv.reader(html, delimiter=\"\\t\")\n",
        "    labels = [row[1] for row in csvreader if len(row) > 1]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBPYtioTIEX4",
        "outputId": "72a397de-6317-47cb-9330-4b2cd1f53f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# STEP 3: Define sentiment function\n",
        "# -----------------------------\n",
        "def sentiment(text):\n",
        "    if pd.isna(text):  # Check for NaN or None\n",
        "        return \"Neutral\" # Or any other default sentiment for missing values\n",
        "\n",
        "    text = text[:1500]   # truncate manually (optional safeguard)\n",
        "    encoded_input = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512   # ✅ explicitly set max_length\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_input)\n",
        "    scores = softmax(output.logits[0].cpu().numpy())\n",
        "    label_id = np.argmax(scores)\n",
        "    return labels[label_id]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cx9WFgq_IHX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# STEP 4: Apply sentiment analysis\n",
        "# -----------------------------\n",
        "df[\"Sentiment\"] = df[\"text\"].apply(lambda x: sentiment(str(x)))\n",
        "\n"
      ],
      "metadata": {
        "id": "17ERZOPmIPiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"labelled_with_sentiment.csv\", index=False)\n",
        "print(\"Saved labelled_with_sentiment.csv successfully\")\n"
      ],
      "metadata": {
        "id": "IPfPt7-Ot714"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}